# ğŸš€ Quick Start - GitHub AI Agent

## âœ… Cháº¡y Ngay (3 bÆ°á»›c)

### BÆ°á»›c 1: CÃ i Dependencies
```bash
pip install -r requirements.txt
```

### BÆ°á»›c 2: Chá»n LLM Provider

#### Option A: Groq (Khuyáº¿n nghá»‹ - Free & Fast)
```bash
export LLM_PROVIDER=groq
export GROQ_API_KEY=gsk_your_key_here
```
- ÄÄƒng kÃ½ free táº¡i: https://console.groq.com/keys
- Tá»‘c Ä‘á»™: ~300-400 token/s
- KhÃ´ng cáº§n GPU/Ollama

#### Option B: Ollama (Local)
```bash
export LLM_PROVIDER=ollama
# CÃ i Ollama táº¡i: https://ollama.com/download
ollama pull deepseek-coder-v2:16b-instruct-qat
```

#### Option C: OpenAI (Máº¡nh nháº¥t)
```bash
export LLM_PROVIDER=openai
export OPENAI_API_KEY=sk_your_key_here
```

### BÆ°á»›c 3: Khá»Ÿi Äá»™ng Server
```bash
uvicorn src.web.app:app --reload --port=5000
```

Má»Ÿ trÃ¬nh duyá»‡t: **http://127.0.0.1:5000**

---

## ğŸ¯ TÃ­nh NÄƒng

### 1. **Chat vá»›i Codebase**
```
Báº¡n: "TÃ¬m code liÃªn quan Ä‘áº¿n embeddings"
AI: [Tá»± Ä‘á»™ng RAG search 15 file â†’ tráº£ lá»i chÃ­nh xÃ¡c]
```

### 2. **Memory DÃ i Háº¡n**
- Ghi nhá»› toÃ n bá»™ lá»‹ch sá»­ chat
- Tá»± Ä‘á»™ng load 20 message gáº§n nháº¥t
- Persist qua restart server

### 3. **Git Automation**
```
Báº¡n: "commit nhÃ©"
AI: [Auto git add + commit + push]

Báº¡n: "táº¡o branch feature/new-ui"
AI: [Auto git checkout -b feature/new-ui]

Báº¡n: "cÃ³ gÃ¬ thay Ä‘á»•i khÃ´ng?"
AI: [Auto git status + hiá»‡n danh sÃ¡ch file]
```

### 4. **Auto Test & Fix**
```
/autofix           â†’ Cháº¡y all tests, tá»± sá»­a code náº¿u fail
/autofix <file>    â†’ Test file cá»¥ thá»ƒ + auto fix
/test -v           â†’ Run pytest vá»›i custom args
```

### 5. **Slash Commands**
```
/help              â†’ Hiá»‡n hÆ°á»›ng dáº«n
/autofix           â†’ Auto test & fix
/test <args>       â†’ Custom pytest
```

---

## ğŸ“¦ Dependencies ChÃ­nh

```
langchain-groq        # Groq LLM provider
langchain-ollama      # Ollama provider (local)
langchain-huggingface # Free embeddings
langchain-chroma      # Vector store (RAG + Memory)
fastapi               # Web server
uvicorn               # ASGI server
```

---

## âš¡ So SÃ¡nh Providers

| Provider | Tá»‘c Ä‘á»™ | Chi phÃ­ | GPU | Setup |
|----------|--------|---------|-----|-------|
| **Groq** | âš¡âš¡âš¡ Nhanh nháº¥t | ğŸ†“ Free | âŒ KhÃ´ng cáº§n | 5 giÃ¢y |
| Ollama | âš¡âš¡ Trung bÃ¬nh | ğŸ†“ Free | âœ… Cáº§n GPU | 10 phÃºt |
| OpenAI | âš¡âš¡ Tá»‘t | ğŸ’° Tráº£ phÃ­ | âŒ KhÃ´ng cáº§n | 5 giÃ¢y |

**Khuyáº¿n nghá»‹:** DÃ¹ng **Groq** cho dev/test, **OpenAI** cho production.

---

## ğŸ› Troubleshooting

### Lá»—i: "Failed to connect to Ollama"
â†’ Äá»•i sang Groq: `export LLM_PROVIDER=groq`

### Lá»—i: "HuggingFaceEmbeddings not found"
â†’ CÃ i: `pip install langchain-huggingface sentence-transformers`

### Lá»—i: Memory corrupt
â†’ Server tá»± recover, hoáº·c xÃ³a: `rm -rf .memory/`

### Lá»—i: Chroma deprecation warning
â†’ ÄÃ£ fix! DÃ¹ng `langchain-chroma` thay vÃ¬ `langchain-community`

---

## ğŸ“š Cáº¥u TrÃºc Project

```
github-ai-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/          # CodeChatAgent + tools
â”‚   â”œâ”€â”€ config/          # LLM provider settings
â”‚   â”œâ”€â”€ llm/             # Ollama/Groq providers
â”‚   â”œâ”€â”€ tools/           # RAG, Git, AutoFix
â”‚   â”œâ”€â”€ web/             # FastAPI + WebSocket
â”‚   â”œâ”€â”€ memory.py        # Long-term memory
â”‚   â””â”€â”€ utils/           # Logger, helpers
â”œâ”€â”€ .memory/             # Memory vector store
â”œâ”€â”€ .chroma/             # RAG vector store
â””â”€â”€ requirements.txt     # Dependencies
```

---

## ğŸ‰ Features HoÃ n ThÃ nh

- âœ… Multi-provider LLM (Groq/Ollama/OpenAI)
- âœ… RAG Semantic Search (15 file/query)
- âœ… Long-term Memory (20 message history)
- âœ… Git Automation (commit, branch, status)
- âœ… Auto Test & Fix Loop
- âœ… WebSocket Real-time UI
- âœ… No mandatory Ollama dependency

---

**PhÃ¡t triá»ƒn bá»Ÿi:** [@t2m19102001](https://github.com/t2m19102001)  
**NgÃ y cáº­p nháº­t:** 30 Nov 2025  
**Version:** 1.0.0 - Production Ready ğŸš€

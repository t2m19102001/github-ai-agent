# ğŸ¤– GitHub AI Agent - Hybrid (Local + Cloud)

Má»™t AI Agent tá»± Ä‘á»™ng cho GitHub Issues sá»­ dá»¥ng **Hybrid Mode** - káº¿t há»£p Ollama (Local) + HuggingFace (Cloud).

## âœ¨ TÃ­nh nÄƒng

- âœ… **Hybrid Mode**: Cháº¡y Ollama local, fallback sang HuggingFace náº¿u cáº§n
- âœ… Tá»± Ä‘á»™ng phÃ¢n tÃ­ch GitHub Issues
- âœ… Comment lÃªn issue vá»›i AI suggestions chi tiáº¿t
- âœ… Code examples & implementation steps
- âœ… HoÃ n toÃ n miá»…n phÃ­
- âœ… Cháº¡y trÃªn GitHub Actions (24/7)
- âœ… Support Local development
- âœ… Intelligent fallback mechanism

## ğŸš€ Quick Start

### 1. Táº¡o HuggingFace Account (2 phÃºt)

```bash
# VÃ o https://huggingface.co/join
# Signup & xÃ¡c nháº­n email
# VÃ o https://huggingface.co/settings/tokens
# Táº¡o new token vÃ  copy
```

### 2. Setup Repository

```bash
# Clone repo
git clone https://github.com/YOUR_USERNAME/github-ai-agent.git
cd github-ai-agent

# Install dependencies
pip install -r requirements.txt

# Copy env template
cp .env.example .env

# Edit .env
# GITHUB_TOKEN=your_token
# REPO_FULL_NAME=your_username/your_repo
# HUGGINGFACE_TOKEN=your_token
```

### 3. Add GitHub Secrets

Repository Settings â†’ Secrets and variables â†’ Actions

```
GITHUB_TOKEN = your_github_personal_access_token
HUGGINGFACE_TOKEN = your_huggingface_api_token
```

### 4. Test Local

```bash
# Make sure Ollama is running (optional for hybrid mode)
ollama serve

# Trong terminal khÃ¡c
python github_agent_hybrid.py
```

## ğŸ“‹ Cáº¥u hÃ¬nh

### Environment Variables

```env
# Required
GITHUB_TOKEN=ghp_xxxxx...
REPO_FULL_NAME=username/repo

# Local Mode (Ollama) - Optional
OLLAMA_API=http://localhost:11434
OLLAMA_MODEL=mistral

# Cloud Mode (HuggingFace)
HUGGINGFACE_TOKEN=hf_xxxxx...
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.1

# Settings
MODE=hybrid  # hybrid, local, cloud
DEBUG=false
```

### Modes

- **`hybrid`** (Recommended): Thá»­ Ollama trÆ°á»›c, fallback HuggingFace
- **`local`**: Chá»‰ dÃ¹ng Ollama (cáº§n mÃ¡y cháº¡y local)
- **`cloud`**: Chá»‰ dÃ¹ng HuggingFace

## ğŸ› ï¸ Setup Ollama (Optional)

Ollama cho phÃ©p agent cháº¡y 100% local, khÃ´ng cáº§n cloud.

### Install Ollama

1. Download: https://ollama.ai
2. Install & run:
   ```bash
   ollama serve
   ```
3. Download model:
   ```bash
   ollama pull mistral
   ```

### Alternative Models

```bash
ollama pull neural-chat      # Chat optimized
ollama pull llama2           # Powerful but slow
ollama pull orca-mini        # Lightweight
```

## ğŸ“Š CÃ¡ch sá»­ dá»¥ng

### Automatic Trigger

Agent tá»± Ä‘á»™ng cháº¡y khi:
- âœ… Issue má»›i Ä‘Æ°á»£c táº¡o
- âœ… Issue Ä‘Æ°á»£c thÃªm label
- âœ… HÃ ng ngÃ y lÃºc 9 AM UTC
- âœ… Manual trigger (workflow_dispatch)

### Manual Trigger

```bash
# Local
python github_agent_hybrid.py

# GitHub Actions
# VÃ o Actions â†’ GitHub AI Agent â†’ Run workflow
```

### Create Test Issue

```markdown
Title: Optimize this function

Body:
def slow_function(items):
    result = []
    for item in items:
        result.append(item * 2)
    return result

How can I make this faster?
```

Agent sáº½ tá»± Ä‘á»™ng comment vá»›i analysis!

## ğŸ“ˆ Output Example

```
============================================================
ğŸ” Processing Issue #1...
============================================================
ğŸ“Œ Title: Optimize this function
ğŸ‘¤ Author: @your_username
ğŸ“ Status: open

ğŸ¤– AI Analysis generated successfully
âœ… Comment posted on issue
```

## ğŸ”§ Troubleshooting

### GitHub Connection Error

```
âŒ GitHub: [Errno 401] Invalid credentials
```

**Fix**: Kiá»ƒm tra GITHUB_TOKEN cÃ³ Ä‘Ãºng khÃ´ng

### Ollama Connection Error

```
âš ï¸ Ollama: Not available
```

**Fix**: Cháº¡y `ollama serve` hoáº·c switch mode sang cloud

### HuggingFace Error

```
âŒ HuggingFace: 401 Unauthorized
```

**Fix**: Kiá»ƒm tra HUGGINGFACE_TOKEN

### Rate Limiting

**Error**: 403 API rate limit exceeded

**Fix**: Agent tá»± Ä‘á»™ng pause 2s giá»¯a cÃ¡c issues, hoáº·c reduce limit

## ğŸ“Š Performance

### Local Mode (Ollama)
- Response time: ~30-60s (phá»¥ thuá»™c mÃ¡y)
- Cost: Free (100%)
- Privacy: 100% (cháº¡y local)

### Cloud Mode (HuggingFace)
- Response time: ~10-30s
- Cost: Free tier 25k requests/month
- Privacy: Data sent to HuggingFace

### Hybrid Mode
- Tries local first (faster)
- Falls back to cloud (reliable)
- Best of both worlds!

## ğŸ” Security

- âœ… Tokens trong GitHub Secrets (khÃ´ng commit)
- âœ… `.env` file trong `.gitignore`
- âœ… Local mode khÃ´ng gá»­i data ra ngoÃ i
- âœ… Cloud mode qua HTTPS

## ğŸ“ Logs

```bash
# Enable debug mode
DEBUG=true python github_agent_hybrid.py
```

Logs sáº½ show:
- âœ… Which mode is active
- âœ… API calls details
- âœ… Response times
- âœ… Errors & fallbacks

## ğŸš€ Next Steps

1. âœ… Setup account (GitHub + HuggingFace)
2. âœ… Add repository secrets
3. âœ… Create test issue
4. âœ… Watch AI comment
5. âœ… Customize prompts (tuá»³ chá»n)

## ğŸ’¡ Customize Prompts

Edit `github_agent_hybrid.py` â†’ `generate_analysis()` Ä‘á»ƒ change prompt.

Example:

```python
prompt = f"""...
Báº¡n lÃ  security expert. HÃ£y phÃ¢n tÃ­ch security issues...
"""
```

## ğŸ“š Resources

- [GitHub API](https://docs.github.com/en/rest)
- [Ollama](https://ollama.ai)
- [HuggingFace Inference](https://huggingface.co/inference-api)
- [PyGithub](https://pygithub.readthedocs.io/)

## ğŸ“„ License

MIT

---

**Made with â¤ï¸ by GitHub AI Agent**

Questions? Create an issue! ğŸ¯